# -*- coding: utf-8 -*-
"""HW3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/199SRhm9BuEjPb-WHxtg_TdpTiN7mmk0B
"""

from google.colab import drive
drive.mount('/content/gdrive')
import numpy as np
import pandas as pd
from matplotlib import pyplot as plt

velos = np.loadtxt('/content/icevelocity.txt')

z = velos[:, 0]

v = velos[:, 1]

def RMSE(model, actual):
  return np.sqrt(np.nanmean((model - actual) ** 2))

#  question 1
# calculate coefficients of models with degrees 0-4
domain = np.arange(0, 182, 2)

fit0 = np.polyval(np.polyfit(z, v, 0), domain)
fit1 = np.polyval(np.polyfit(z, v, 1), domain)
fit2 = np.polyval(np.polyfit(z, v, 2), domain)
fit3 = np.polyval(np.polyfit(z, v, 3), domain)
fit4 = np.polyval(np.polyfit(z, v, 4), domain)

print('Qustion #1')

plt.plot(domain, fit0, label=f'Degree 0, RMSE = {round(RMSE(fit0, v), 2)}')
plt.plot(domain, fit1, label=f'Degree 1, RMSE = {round(RMSE(fit1, v), 2)}')
plt.plot(domain, fit2, label=f'Degree 2, RMSE = {round(RMSE(fit2, v), 2)}')
plt.plot(domain, fit3, label=f'Degree 3, RMSE = {round(RMSE(fit3, v), 2)}')
plt.plot(domain, fit4, label=f'Degree 4, RMSE = {round(RMSE(fit4, v), 2)}')
plt.scatter(z, v, label='Data', color='black', linewidth=0.15)
plt.title('Degree 0-4 Polynomial Estimates')
plt.xlabel('Depth (m)')
plt.ylabel('Velocity (m/yr)')
plt.legend()

plt.show()

# question 2
def getTrainTest(caca, pTrain):
    """
    partitions data set into training subset and testing subset
    :param caca: data set
    :param pTrain: % of data set used to train model
    :return: two arrays
    """
    pTrain /= 100  # decimal conversion
    ns = len(caca)  # number of samples
    nsTrain = int(round(pTrain * ns))  # pTrain% of samples of caca
    Ix = np.array(range(ns))  # list of indexes of caca

    train_index = np.random.choice(sorted(Ix), nsTrain, replace=False)  # nsTrain number of random samples
    train_set = caca[train_index]  # the set used to train model

    test_index = np.ones(len(Ix))  # create an array of 1's to build indices of testing set
    #  looks through indices of data used to train, and swaps 1 to 0 in corresponding indices
    for i in train_index:
        test_index[i] = 0
    test_set = caca[test_index == 1]  # builds test sets from test_index

    return train_set, test_set

def monte_carlo_param(caca, degree, percent, trials = 1000):
    '''
    monte carlo for selecting random data and fitting model to that data
    :param caca: dataset
    :param trials: number of simulation to run
    :param percent: percent of data to sample.  enter whole numbers
    :return:
    '''
    coef_df = np.zeros((trials, degree + 1))
    for i in range(trials):
        data_subset = getTrainTest(caca, percent)[0]
        coef_df[i] = np.polyfit(data_subset[:,0], data_subset[:,1], degree)
    return coef_df

def monte_stat_table(caca, degree):
    '''
    creates a pandas dataframe for the mean and standard deviation of coefficients returned from monte_carlo_param
    :param caca: return from monte_carlo_param
    :param degree: highest degree, must match number of columns from caca.  probably easy way to remove this param.  it's late and can't be bothered
    :return: summary stat table, a pd.DataFrame
    '''
    col_names = ['mean', 'std']
    summary_stats = []
    i = degree
    row_names = []
    while i >= 0:
        row_names.append(f"x^{i}")
        i -= 1
    for col in range(np.shape(caca)[1]):
        col_mean = np.mean(caca[:, col])
        col_std = np.std(caca[:, col])
        summary_stats.append([col_mean, col_std])

    summary_stats = pd.DataFrame(summary_stats, columns=col_names, index=row_names)
    return summary_stats



monte0 = monte_carlo_param(velos, 0, 90)
monte1 = monte_carlo_param(velos, 1, 90)
monte2 = monte_carlo_param(velos, 2, 90)
monte3 = monte_carlo_param(velos, 3, 90)
monte4 = monte_carlo_param(velos, 4, 90)

print('Question #2')

print('Average coefficient for each model, standard deviation of each coefficient')
print(monte_stat_table(monte0, 0))
print()
print(monte_stat_table(monte1, 1))
print()
print(monte_stat_table(monte2, 2))
print()
print(monte_stat_table(monte3, 3))
print()
print(monte_stat_table(monte4, 4))

'''
Creates 1000 partitions of ice velocities dataset into 90/10 splits.  Defined here so don't need
to re-define each time it's needed
'''
all_x_train = np.zeros((82, 1000))
all_y_train = np.zeros((82, 1000))
all_x_test = np.zeros((9, 1000))
all_y_test = np.zeros((9, 1000))
for i in range(1000):
  partition = getTrainTest(velos, 90)
  trainset = partition[0]
  testset = partition[1]

  all_x_train[:, i] = trainset[:, 0]
  all_y_train[:, i] = trainset[:, 1]

  all_x_test[:, i] = testset[:, 0]
  all_y_test[:, i] = testset[:, 1]

#  question 3
def cross_val(x_train, y_train, x_test, y_test, degree):
  '''
  cross validation function
  input: x_train ==> array of x-values of training data
          y_train ==> array of y-values of training data
          x_test ==> array of x-values of testing data
          y_test ==> array of y-values of testing data
          degree ==> degree of polynomial model
  output: RMSE
  '''
  train_coef = np.polyfit(x_train, y_train, degree)
  train_func = np.polyval(train_coef, x_test)
  return RMSE(train_func, y_test)


def monte_rmse(trials = 1000, percent = 90, degree = 3):
    '''
    monte-carlo simulation for cross validation
    :param trials: # of trials
    :param caca: 2D dataset
    :param degree: highest degree of parametric polynomial model
    :param percent: whole number percent to partition dataset
    :return: 1 x tirals rmse for each trial
    '''
    deg_rmse = np.zeros((trials, 1))
    for i in range(0, trials):
        deg_rmse[i] = cross_val(all_x_train[:, i], all_y_train[:, i], all_x_test[:, i], all_y_test[:, i], degree)
    return deg_rmse


deg0_rmse = monte_rmse(degree=0)
deg1_rmse = monte_rmse(degree=1)
deg2_rmse = monte_rmse(degree=2)
deg3_rmse = monte_rmse(degree=3)
deg4_rmse = monte_rmse(degree=4)

print('Question #3')
plt.figure(figsize=(8,10))
plt.subplot(5,1,1)
plt.title('RMSE for 1000 trials')
plt.xlim(0, 10)
plt.hist(deg0_rmse, 40, density=True)
plt.subplot(5,1,2)
plt.xlim(0, 10)
plt.hist(deg1_rmse, 40, density=True)
plt.subplot(5,1,3)
plt.xlim(0, 10)
plt.hist(deg2_rmse, 25, density=True)
plt.subplot(5,1,4)
plt.xlim(0, 10)
plt.hist(deg3_rmse, 25, density=True)
plt.subplot(5,1,5)
plt.xlim(0, 10)
plt.hist(deg4_rmse, 25, density=True)
plt.xlabel('RMSE')


plt.show()

# Question 4: moving window average with window size of 3, 10, 50

def mov_avg(x_train, y_train, w_size):
  '''
  moving average function
  input: x_train ==> array of x-values of training data
          y_train ==> array of y-values of training data
          w_size ==> window size
  output: RMSE
  '''
  mov_mean = np.zeros(len(x_train))
  for i in range(len(x_train)):
    xlow = x_train[i] - w_size / 2  # set upper and lower bounds of window
    xhigh = x_train[i] + w_size / 2
    Ix = np.logical_and(x_train > xlow, x_train < xhigh)  #find indices of points in window
    window_average = np.nanmean(y_train[Ix])  #calculate average of y values in window
    mov_mean[i] = window_average  #add average to array
  return mov_mean




mwa3 = mov_avg(z, v, 3)
mwa10 = mov_avg(z, v, 10)
mwa50 = mov_avg(z, v, 50)

print('Question 4')
plt.plot(domain, mwa3, label='Window size: 3')
plt.plot(domain, mwa10, label='Window size: 10')
plt.plot(domain, mwa50, label='Window size: 50')
plt.scatter(z, v, label='Data', color='black', linewidth=0.15)
plt.title('Moving Window Average')
plt.xlabel('Depth (m)')
plt.ylabel('Velocity (m/yr)')
plt.legend()
plt.show()

print('Question 5')

def wei_mov_avg(train_x, train_y, test_x, w_size):
  '''
  Function to calculate moving weighted average
  inputs:
    train_x:  x-data set for training
    train_y:  y-data set for training
    test_x:   x-data set for testing, although in three function calls below, this is the same as train_x
    w_size:   window size
  outputs:
    mov_mean: moving weighted average
  '''
  mov_mean = np.zeros(len(test_x))
  for i in range(len(test_x)):
    xlow = test_x[i] - w_size / 2  # define window
    xhigh = test_x[i] + w_size / 2
    Ix = np.logical_and(train_x > xlow, train_x < xhigh)  # get indices of x_vals in training set that fall within window
    y_mod = train_y[Ix]  # define x and y of the training set
    x_mod = train_x[Ix]
    weights = np.zeros(len(y_mod))
    for j in range(len(x_mod)):
      # calculate weights defined by x_mod and x-coords of train set
      weights[j] = (15 / 16) * (1 - ((x_mod[j] - test_x[i]) / (w_size / 2)) ** 2) ** 2
    mov_mean[i] = np.dot(weights, y_mod) / np.sum(weights)
  return mov_mean

weighted_mwa3 = wei_mov_avg(z, v, z,  3)
weighted_mwa10 = wei_mov_avg(z, v, z, 10)
weighted_mwa50 = wei_mov_avg(z, v, z, 50)


plt.figure(figsize=(7,7))
plt.plot(z, weighted_mwa3, label='Window size: 3')
plt.plot(z, weighted_mwa10, label='Window size: 10')
plt.plot(z, weighted_mwa50, label='Window size: 50')
plt.scatter(z, v, label='Data', color='black', linewidth=0.15)
plt.title('Weighted Moving Window Average')
plt.xlabel('Depth (m)')
plt.ylabel('Velocity (m/yr)')
plt.legend()
plt.show()

print('Question 6')
'''
Finds the optimal window size by training a model on 90% of data and calculating RMSE on remaining 10%
'''

summary_window_rmse = np.zeros((180))

for w in range(len(np.linspace(0, 180, 180))):
  window_rmse = np.zeros(1000)
  for ix in range(1000):
    data_x = all_x_test[:, ix]
    data_y = all_y_test[:, ix]
    y_model = wei_mov_avg(all_x_train[:, ix], all_y_train[:, ix], all_x_test[:, ix], w)
    window_rmse[ix] = RMSE(y_model, data_y)

  summary_window_rmse[w] = np.nanmean(window_rmse)





plt.plot(np.linspace(0, 60, 180), summary_window_rmse)

print('Question 7')

# define contstants for ice flow model
u_surf = v[0]
rho = 917
theta = 10
g = 9.81

# Calculate best values for A0 and n using brute force
A0 = np.linspace(1e-18, 1e-17, 1000) # range of A0
exp = np.linspace(2, 4, 1000)  # range A1
phys_error = np.zeros((len(A0), len(exp))) #5 initialize rmse

# run model and calculate RMSE for each value of A0 and n (where n is the exponenet)
for n in range(len(A0)):
    for n2 in range(len(exp)):
        phys_model = u_surf - (A0[n] * (rho * g * np.sin(np.radians(theta))) ** exp[n2]) * (z ** (exp[n2] + 1))
        phys_error[n2, n] = np.sqrt(np.mean((phys_model - v) ** 2))

#  phys_error is stored as a 2D array, next line returns the row containing smallest RMSE
minrmse = np.unravel_index(np.argmin(phys_error), phys_error.shape)

best_A = round(A0[minrmse[1]],4)
best_exp = round(exp[minrmse[0]],4)
opt_rmse = round(np.min(phys_error),4)
print('Question 7')
print(best_A, best_exp)
print(opt_rmse)

print('Question 8')
#  Plot heat map of RMSE values for different A_0 and n values
plt.imshow(phys_error, extent=(A0.min(), A0.max(), exp.min(), exp.max()), aspect='auto',
           origin='lower', cmap='viridis', vmin=0, vmax=40)
plt.xlabel('A0')
plt.ylabel('exp')
plt.plot(best_A, best_exp, 'ro', linewidth=2, markersize=10)
plt.colorbar(label='RMSE')
plt.title('Optimal values for A0 and n in ice flow equation')
plt.show()

# Question 9
# Find values for A0 and n using minimize function
# To fix issues where python wouldn't return precise enough numbers,
#   calculate best value of A_0(rho*g*sin(theta))^n then divide
# Set exponent to 4
from scipy.optimize import minimize
gradient_domain = np.linspace(0, 180, 91)

def RMSEval(param):
    big_A = param  # Unpack parameters
    vel_model = u_surf - big_A * (z ** (3 + 1))
    vel_error = np.sqrt(np.mean((vel_model - v) ** 2))
    return vel_error



guess = 2.2e-8
result = minimize(RMSEval, guess)
A_0_min = result.x / (rho * g * np.sin(np.radians(theta))) ** 3
print(A_0_min)
print(result)

print('Question 9')
# Plot best A_0 value given an exponent of 3
plt.imshow(phys_error, extent=(A0.min(), A0.max(), exp.min(), exp.max()), aspect='auto',
           origin='lower', cmap='viridis', vmin=0, vmax=40)
plt.xlabel('A0')
plt.ylabel('exp')
plt.plot(best_A, best_exp, 'r', marker='o', linewidth=2, label='Brute Force')
plt.colorbar(label='RMSE')
plt.plot(A_0_min, 3, marker='x', color='cyan', label='Minimize Function', markersize=10)
plt.legend()
plt.title('Optimal values for A0 and n in ice flow equation')

plt.show()

# Question 10
#Calculate the best value for A and RMSE for 1000 subsets of training data
A0_error = np.zeros((1000, 2))
n = best_exp
for ix in range(1000):
    x_training = all_x_train[:, ix]
    y_training = all_y_train[:, ix]
    def RMSEval(param):
      big_A = param  # Unpack parameters
      vel_model = u_surf - big_A * (x_training ** (3 + 1))
      vel_error = np.sqrt(np.mean((vel_model - y_training) ** 2))
      return vel_error
    this_result = minimize(RMSEval, 2e-8)
    A0_error[ix, 0] = this_result.fun
    A0_error[ix, 1] = this_result.x / (rho * g * np.sin(np.radians(theta))) ** 3

print(A0_error)

plt.subplot(1,2,1)
plt.hist(A0_error[:, 0], bins=30, density=True, edgecolor='black')
plt.title("RMSE")
plt.subplot(1,2,2)
plt.hist(A0_error[:, 1], bins=30, density=True, edgecolor='black')
plt.title('A Values')
plt.show()

print('Question 11')
# From 1000 trials, calculate the average and std of the A_0 values using 90% of the dataset

plt.figure(figsize=(8,8))
plt.imshow(phys_error, extent=(A0.min(), A0.max(), exp.min(), exp.max()), aspect='auto',
           origin='lower', cmap='viridis', vmin=0, vmax=40)
plt.xlabel('A0')
plt.ylabel('exp')
plt.plot(best_A, best_exp, 'r', marker='o', linewidth=2, label='Brute Force')
plt.colorbar(label='RMSE')
plt.plot(A_0_min, 3, marker='x', color='cyan', label='Minimize Function', markersize=10)
plt.legend()
# plot average and error bars
plt.errorbar(np.mean(A0_error[:, 1]), 3, xerr=np.std(A0_error[:, 1]),
             fmt='x', color='orange', label='1000 trials', markersize=5)
plt.legend()
plt.title('Optimal values for A0 and n in ice flow equation')


plt.show()

print('Question 12')
# create a normally distributed dataset of 1000 values using mean and std. of best values for A_0 and the associated RMSE
mean_A = np.mean(A0_error[:, 1])
std_A = np.std(A0_error[:, 1])
sim_A = np.random.normal(mean_A, std_A, 1000)

mean_RMSE = np.mean(A0_error[:, 0])
std_RMSE = np.std(A0_error[:, 0])
sim_RMSE = np.random.normal(mean_RMSE, std_RMSE, 1000)

from scipy.stats import ks_2samp
# calculate p-value comparing normally distributed A_0 and RMSE (from above) and
#   1000 values of A_0 and RMSE found from monte-carlo simulations
A_stat, A_p = ks_2samp(sim_A, A0_error[:, 1])

print(f'KS-stat for A: {A_stat}\n'
      f'p-value for A: {A_p}')

RMSE_stat, RMSE_p = ks_2samp(sim_RMSE, A0_error[:, 0])
print(f'KS-stat for RMSE: {RMSE_stat}\n'
      f'p-value for RMSE: {RMSE_p}')